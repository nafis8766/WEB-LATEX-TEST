\section*{Abstract}
Large Language Models (LLMs) are highly effective at  finding and generating information. Still they are difficult to use on devices with limited processing capacity like smartphones as they require a lot of computing power. This thesis focuses on creating a smaller and more efficient Retrieval-Augmented Generation (RAG) model. The model will be specifically designed to work with Bangladeshâ€™s legal system. To make the model lighter and faster, we will use LLM distillation . This process removes the unnecessary parts of a large model while keeping its ability of finding and generating desired information from a specific domain. The goal is to reduce the model size to less than under a billion parameters. Our approach will make sure that the model works smoothly on personal devices like smartphones even without internet access. This is especially important for the people of Bangladesh where access to the internet can be unreliable in many areas. This research will explore effective distillation strategies , domain specific knowledge incorporation and retrieval mechanisms without compromising legal accuracy for achieving the goal. The final result of this study will help to reduce technology gaps by providing a user-friendly, trustworthy and efficient AI tool. It will help people in Bangladesh access legal information more easily , understand laws better and make smarter legal decisions.

\vspace{1cm}
\textbf{Keywords: Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), LLM distillation, Legal system of Bangladesh, Model efficiency, Offline access, Legal accuracy, Knowledge retrieval} 
\pagebreak
